{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.vq import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'normalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a135ec20cd8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess_powered_sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misDataRise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_spectrum_with_fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspecial_items\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchart_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_data_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'normalization'"
     ]
    }
   ],
   "source": [
    "from normalization import process_powered_sheet\n",
    "from analysis import isDataRise, power_spectrum_with_fitting\n",
    "from special_items import cluster_k, sampling_frequency, chart_dir, eye_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = process_powered_sheet()\n",
    "ch_num, data, on_thresh, _ = temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 9.21163544297e-05\n",
    "on_thresh = 9*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_raw = np.sign(data['power'].values-on_thresh) #NOTE: skip kde analysis；不做KDE，仅对power后的数据减去阈值后取Sign值；由于历史原因，变量名就没有改。\n",
    "#kde_raw = kde_anaylsis(data[data.spike > 0]['time'].values[:,np.newaxis], data['time'].values).flatten()\n",
    "kde_result = pd.DataFrame(np.hstack((data['time'].values[:,np.newaxis], np.sign(kde_raw)[:,np.newaxis])),columns=['time','kde_spike'])\n",
    "\n",
    "isSeekingRise = 1\n",
    "bout_time_list = []\n",
    "print('check data rise:')\n",
    "for each_pos in tqdm(kde_result[kde_result.kde_spike > 0].index): #REVIEW\n",
    "    if isDataRise(kde_result, each_pos, step=isSeekingRise):\n",
    "        bout_time_list.append(kde_result.iloc[each_pos]['time'])\n",
    "        isSeekingRise = - isSeekingRise\n",
    "\n",
    "#NB: bout_time_pair: list[(start, end, name)]\n",
    "bout_time_pair = [(bout_time_list[index*2], bout_time_list[index*2+1], 'bout_%d'%index) for index in range(int(len(bout_time_list)/2))]\n",
    "bout_time_pair = list(filter(lambda x:x[1]-x[0]>10/sampling_frequency, bout_time_pair)) #REVIEW: XXX: 跳过长度小于0.01，即不足10个数据点的数据段\n",
    "\n",
    "popt_list, out_name = power_spectrum_with_fitting(data, bout_time_pair, ch_num, isPlot=False) #数据拟合\n",
    "bout_time_pair = [x for x in bout_time_pair if x[-1] not in out_name]\n",
    "\n",
    "mean_list = [(data[(data.time >= start) & (data.time <= end)]['raw'].mean(),name) for start, end, name in bout_time_pair]\n",
    "argument_list = [(popt_list[index][0], popt_list[index][1], mean_list[index][0], mean_list[index][1]) for index in range(len(mean_list))]\n",
    "exile_name = [x[-1] for x in argument_list if x[1] < -10]      #REVIEW\n",
    "argument_list = list(filter(lambda x:x[1]>-10, argument_list)) #REVIEW\n",
    "bout_time_pair = [x for x in bout_time_pair if x[-1] not in exile_name]\n",
    "\n",
    "#k-means clustering\n",
    "#NB:codebook: np.array([A, tau, C])\n",
    "codebook, distortion = kmeans(list(map(lambda x:x[:3],argument_list)),cluster_k) #TODO: modifier other parameters\n",
    "print('k-means result:', codebook, distortion)\n",
    "\n",
    "#cluster and delete data\n",
    "#NB: scatter_result:list[(A, tau, mean, name, genre)]\n",
    "scatter_result = []\n",
    "for item in argument_list:\n",
    "    distance1 = np.sqrt((item[0]-codebook[0][0])**2+(item[1]-codebook[0][1])**2+(item[2]-codebook[0][2])**2)\n",
    "    distance2 = np.sqrt((item[0]-codebook[1][0])**2+(item[1]-codebook[1][1])**2+(item[2]-codebook[1][2])**2)\n",
    "    genre = 1 if distance1 > distance2 else 2\n",
    "    scatter_result.append((item[0], item[1], item[2], item[3], genre))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ch_num == 1: #CHANGED: 跳过Ch 0通道；仅仅是为了方便分析Ch 1的数据。\n",
    "    eye = pd.read_csv(eye_data_path) #NOTE:\n",
    "    for index in eye.index:\n",
    "        plt.plot(eye.iloc[index].tolist(), np.zeros(eye.iloc[index].shape)-on_thresh*2,c='black',linewidth=2.5)\n",
    "\n",
    "\n",
    "plt.xlim(data['time'].values[0], data['time'].values[-1])\n",
    "plt.savefig(os.path.join(chart_dir,'R_raw_CH_%d.png'%ch_num), bbox_inches='tight')\n",
    "\n",
    "#TODO: 自动分割\n",
    "for start, end in [(60,500),(500,1000),(1000,1500),(1500,2000)]:#,\n",
    "                           #(2000,2500),(2500,3000),(3000,3500),(3500,4000),\n",
    "                           #(4000,4500),(4500,5000),(5000,5500),(5500,6000),\n",
    "                           #(6000,6500),(6500,7000),(7000,7500),(7500,8000)]:\n",
    "    plt.xlim(start, end)\n",
    "    plt.savefig(os.path.join(chart_dir,'R_raw_CH_%d_%d_%d.png'%(ch_num,start,end)), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print('CH_%d processed'%ch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "# SATM\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(x=[x for _,x,_,_,_ in scatter_result ], y=[y for _,_,y,_,_ in scatter_result],s=50, c=['g' if c==1 else 'r' for _,_,_,_,c in scatter_result])#REVIEW , s=[-np.log10(z) for z,_,_ in argument_list])\n",
    "for _,x,y, in codebook:\n",
    "    plt.scatter(x=x,y=y,s=100,c='#808080')\n",
    "#plt.xlim(-3,7)\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_?->raw, kde, data_rise, chew_bout\n",
    "plt.figure(figsize=(100,10))\n",
    "plt.plot(data['time'].values, data['power'].values,'pink')\n",
    "plt.plot(data['time'].values, np.ones(data['time'].values.shape)*on_thresh, c='#808080')\n",
    "            #plt.plot(data['time'].values, np.ones(data['time'].values.shape)*off_thresh, 'r'))\n",
    "            #axes[0].xlim(data['time'].values[0],data['time'].values[-1])\n",
    "bout_height = data['power'].values.max()\n",
    "\n",
    "for index in range(len(bout_time_pair)): #scatter_result:list[(A, tau, mean, name, genre)]\n",
    "    if scatter_result[index][-1] == 1:\n",
    "        color = 'g'\n",
    "    else:\n",
    "        color = 'r'\n",
    "    target_time = data[(data.time>=bout_time_pair[index][0]) & (data.time<=bout_time_pair[index][1])]['time'].values\n",
    "    plt.plot(target_time, np.zeros(target_time.shape)-on_thresh,c=color,linewidth=2.5)\n",
    "if ch_num == 1: #CHANGED: 跳过Ch 0通道；仅仅是为了方便分析Ch 1的数据。\n",
    "    eye = pd.read_csv(eye_data_path) #NOTE:\n",
    "    for index in eye.index:\n",
    "        plt.plot(eye.iloc[index].tolist(), np.zeros(eye.iloc[index].shape)-on_thresh*2,c='black',linewidth=2.5)\n",
    "\n",
    "#TODO: 自动分割\n",
    "for start, end in [(60,500)]:\n",
    "    plt.xlim(start, end)\n",
    "    plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('CH_%d processed'%ch_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
